\section{Approach}  \label{approach}

\subsection{Dataset Creation}  \label{ch:approachA}
% Choosing latest mutations that are the most spread
% Created three types of sequence pairs: (real, real), (real, generated), (real, unreal)
% Phylogenetic tree with "Fasttree"
% Levenshtein distance
% Biopython packages?
% Final dataset metrics

\subsection{Data Preprocessing}  \label{ch:approachB}
% TODO: Pipeline image
% Word size 3 is just a hyperparameter (see discussion of the corresponding paper)!  But maybe biologically valid because auf amino acids.
% DNA2Vec?

\begin{itemize}
	\item DNA Sequencing (Done during dataset creation, given from GISAID)
	\item DNA Sequence Tokenization for Amino Acid Dictionary
	\item DNA Sequence Padding
\end{itemize}

\subsection{Model Architecture}  \label{ch:approachC}
% Hyperparameters and model architecture
% Reference http://nlp.seas.harvard.edu/2018/04/03/attention.html if one wants to build it by oneself

\subsection{Training Process} \label{ch:approachD}
% Plot accuracy and loss for training and validation
% Loss functions and teacher forcing, early stopping?
% Categorical cross-entropy loss for seq2seq, Wasserstein loss for GAN, kullback leibner + cross entropy for transformers
% Identify changes between sequences using the diff-match package from Google
% See MutaGAN 6.2 Model training
% Replay buffer
% Dealing with the mode collapse problem

\newpage
